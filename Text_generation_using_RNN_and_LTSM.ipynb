{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "ngg9ISnVbWNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "text_df = pd.read_csv(\"/content/fake_or_real_news.csv\")"
      ],
      "metadata": {
        "id": "0Vtx3KWDbZxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine text data into a single string\n",
        "text = list(text_df.text.values)\n",
        "joined_text = \" \".join(text)"
      ],
      "metadata": {
        "id": "Xjq35ZzmbiB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a partial text from the beginning\n",
        "partial_text = joined_text[:10000]"
      ],
      "metadata": {
        "id": "6HD1wgzzblRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text using regular expression\n",
        "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "tokens = tokenizer.tokenize(partial_text.lower())"
      ],
      "metadata": {
        "id": "HnD3CpcDbleA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find unique tokens and create a dictionary for mapping tokens to indices\n",
        "unique_tokens = np.unique(tokens)\n",
        "unique_token_index = {token: idx for idx, token in enumerate(unique_tokens)}"
      ],
      "metadata": {
        "id": "gMlUvkWebwsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of words for the input sequence\n",
        "n_words = 10\n",
        "input_words = []\n",
        "next_words = []"
      ],
      "metadata": {
        "id": "4JaI7B6Pbw5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input and output sequences for the model\n",
        "for i in range(len(tokens) - n_words):\n",
        "    input_words.append(tokens[i:i + n_words])\n",
        "    next_words.append(tokens[i + n_words])"
      ],
      "metadata": {
        "id": "p7I6H4Ucb7sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the input and output arrays\n",
        "X = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)\n",
        "y = np.zeros((len(next_words), len(unique_tokens)), dtype=bool)"
      ],
      "metadata": {
        "id": "LF9eybT3b7zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert input and output sequences into a suitable format for the model\n",
        "for i, words in enumerate(input_words):\n",
        "    for j, word in enumerate(words):\n",
        "        X[i, j, unique_token_index[word]] = 1\n",
        "    y[i, unique_token_index[next_words[i]]] = 1"
      ],
      "metadata": {
        "id": "ca1Q3OsLb75f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN Model\n",
        "# Create a sequential model\n",
        "rnn_model = Sequential()"
      ],
      "metadata": {
        "id": "zBR2BIHlb7_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a simple RNN layer with 128 units\n",
        "rnn_model.add(SimpleRNN(128, input_shape=(n_words, len(unique_tokens),), return_sequences=True))\n",
        "rnn_model.add(SimpleRNN(128))"
      ],
      "metadata": {
        "id": "UaBOD56AcT7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a dense layer with the number of unique tokens and a softmax activation function\n",
        "rnn_model.add(Dense(len(unique_tokens)))\n",
        "rnn_model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "wQ-o322DcUCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the RNN model with appropriate loss function, optimizer, and metrics\n",
        "rnn_model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(learning_rate=0.01), metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "IKoEyMpkcUHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the RNN model using the training data\n",
        "rnn_model.fit(X, y, batch_size=128, epochs=30, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cetaunecn1D",
        "outputId": "de3c34ad-188b-4bce-97b4-857ec5e25707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "14/14 [==============================] - 2s 34ms/step - loss: 6.9907 - accuracy: 0.0166\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 6.5228 - accuracy: 0.0246\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 6.4462 - accuracy: 0.0338\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 6.4622 - accuracy: 0.0309\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 6.4027 - accuracy: 0.0320\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 6.7954 - accuracy: 0.0252\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 6.4434 - accuracy: 0.0349\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - 0s 34ms/step - loss: 6.4406 - accuracy: 0.0338\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 6.4079 - accuracy: 0.0269\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - 0s 34ms/step - loss: 6.5194 - accuracy: 0.0229\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 6.4862 - accuracy: 0.0332\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 6.6052 - accuracy: 0.0326\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 6.5210 - accuracy: 0.0309\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 6.5198 - accuracy: 0.0326\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - 0s 34ms/step - loss: 6.5052 - accuracy: 0.0366\n",
            "Epoch 16/30\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 6.5008 - accuracy: 0.0435\n",
            "Epoch 17/30\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 6.5456 - accuracy: 0.0320\n",
            "Epoch 18/30\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 6.7368 - accuracy: 0.0206\n",
            "Epoch 19/30\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 6.6282 - accuracy: 0.0343\n",
            "Epoch 20/30\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 6.5293 - accuracy: 0.0418\n",
            "Epoch 21/30\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 6.5201 - accuracy: 0.0349\n",
            "Epoch 22/30\n",
            "14/14 [==============================] - 1s 54ms/step - loss: 6.5246 - accuracy: 0.0297\n",
            "Epoch 23/30\n",
            "14/14 [==============================] - 1s 55ms/step - loss: 6.5195 - accuracy: 0.0343\n",
            "Epoch 24/30\n",
            "14/14 [==============================] - 1s 55ms/step - loss: 6.5247 - accuracy: 0.0292\n",
            "Epoch 25/30\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 6.5007 - accuracy: 0.0389\n",
            "Epoch 26/30\n",
            "14/14 [==============================] - 0s 34ms/step - loss: 6.5015 - accuracy: 0.0275\n",
            "Epoch 27/30\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 6.5099 - accuracy: 0.0286\n",
            "Epoch 28/30\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 6.5186 - accuracy: 0.0360\n",
            "Epoch 29/30\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 6.5083 - accuracy: 0.0412\n",
            "Epoch 30/30\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 6.4739 - accuracy: 0.0240\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e84440d7d00>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the RNN model\n",
        "rnn_model.save(\"mymodel_rnn.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LfAWrC3cn7j",
        "outputId": "aa381bd1-5ca2-4437-c750-7c323252c1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Model\n",
        "# Create a sequential model\n",
        "lstm_model = Sequential()"
      ],
      "metadata": {
        "id": "yxgoIzaIcv4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an LSTM layer with 128 units\n",
        "lstm_model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
        "lstm_model.add(LSTM(128))"
      ],
      "metadata": {
        "id": "03j9f1oScwAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a dense layer with the number of unique tokens and a softmax activation function\n",
        "lstm_model.add(Dense(len(unique_tokens)))\n",
        "lstm_model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "n-CW2AUhcwGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the LSTM model with appropriate loss function, optimizer, and metrics\n",
        "lstm_model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(learning_rate=0.01), metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "EnJWC2AKcwLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the LSTM model using the training data\n",
        "lstm_model.fit(X, y, batch_size=128, epochs=30, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4kqDH7_cwRz",
        "outputId": "5c3cd85a-464f-4289-a06f-4ae9e5de8e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "14/14 [==============================] - 5s 119ms/step - loss: 6.2298 - accuracy: 0.0366\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - 2s 135ms/step - loss: 5.8606 - accuracy: 0.0618\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 5.8086 - accuracy: 0.0618\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 5.7877 - accuracy: 0.0618\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 5.7531 - accuracy: 0.0618\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 5.6958 - accuracy: 0.0618\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 5.6402 - accuracy: 0.0618\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 5.5644 - accuracy: 0.0601\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 5.4086 - accuracy: 0.0761\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 5.2418 - accuracy: 0.0830\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - 2s 145ms/step - loss: 5.0116 - accuracy: 0.0978\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - 1s 103ms/step - loss: 4.7946 - accuracy: 0.1013\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 4.5505 - accuracy: 0.1098\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 4.2302 - accuracy: 0.1453\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 3.9247 - accuracy: 0.1573\n",
            "Epoch 16/30\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 3.5914 - accuracy: 0.1968\n",
            "Epoch 17/30\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 3.2150 - accuracy: 0.2408\n",
            "Epoch 18/30\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 2.8810 - accuracy: 0.3026\n",
            "Epoch 19/30\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 2.4795 - accuracy: 0.3965\n",
            "Epoch 20/30\n",
            "14/14 [==============================] - 2s 116ms/step - loss: 2.1911 - accuracy: 0.4668\n",
            "Epoch 21/30\n",
            "14/14 [==============================] - 2s 136ms/step - loss: 1.8566 - accuracy: 0.5698\n",
            "Epoch 22/30\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 1.4965 - accuracy: 0.6773\n",
            "Epoch 23/30\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 1.2332 - accuracy: 0.7614\n",
            "Epoch 24/30\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.9895 - accuracy: 0.8255\n",
            "Epoch 25/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.7504 - accuracy: 0.8833\n",
            "Epoch 26/30\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.5805 - accuracy: 0.9279\n",
            "Epoch 27/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.4573 - accuracy: 0.9468\n",
            "Epoch 28/30\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.3597 - accuracy: 0.9554\n",
            "Epoch 29/30\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2549 - accuracy: 0.9783\n",
            "Epoch 30/30\n",
            "14/14 [==============================] - 2s 147ms/step - loss: 0.1192 - accuracy: 0.9954\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e844f858520>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the LSTM model\n",
        "lstm_model.save(\"mymodel_lstm.h5\")"
      ],
      "metadata": {
        "id": "-Aj-avuBdHGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict the next word based on the input text and the trained model\n",
        "def predict_next_word(model, input_text, n_best, unique_tokens, unique_token_index, n_words):\n",
        "    input_text = input_text.lower()\n",
        "    X = np.zeros((1, n_words, len(unique_tokens)))\n",
        "    for i, word in enumerate(input_text.split()):\n",
        "        X[0, i, unique_token_index[word]] = 1\n",
        "\n",
        "    predictions = model.predict(X)[0]\n",
        "    return np.argpartition(predictions, -n_best)[-n_best:]"
      ],
      "metadata": {
        "id": "MIYCP7zwdL4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate text based on the input text and the trained model\n",
        "def generate_text(model, input_text, text_length, creativity, unique_tokens, unique_token_index, n_words):\n",
        "    word_sequence = input_text.split()\n",
        "    current = 0\n",
        "    for _ in range(text_length):\n",
        "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current + n_words])\n",
        "        try:\n",
        "            choice = unique_tokens[random.choice(predict_next_word(model, sub_sequence, creativity, unique_tokens, unique_token_index, n_words))]\n",
        "        except:\n",
        "            choice = random.choice(unique_tokens)\n",
        "        word_sequence.append(choice)\n",
        "        current += 1\n",
        "    return \" \".join(word_sequence)"
      ],
      "metadata": {
        "id": "TwB80P1PdSZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text using the RNN model\n",
        "generated_text_rnn = generate_text(rnn_model, \"He will have to look into this thing and he\", 100, 5, unique_tokens, unique_token_index, n_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqBEMmtUdXt5",
        "outputId": "5d63b576-4360-4478-8aab-2462d98688bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 221ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text using the LSTM model\n",
        "generated_text_lstm = generate_text(lstm_model, \"He will have to look into this thing and he\", 100, 5, unique_tokens, unique_token_index, n_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6PcbjZ4dc8e",
        "outputId": "575719f5-9409-42e6-872f-36dd32c79570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 753ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the generated texts RNN\n",
        "print(\"Generated Text (RNN): \", generated_text_rnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBXAzNgcdjY2",
        "outputId": "fb7438e0-e82b-439f-d0d7-48b086ceec2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text (RNN):  He will have to look into this thing and he are a are of the a are the fighting the of fighting fighting a fighting the are a the a the the fighting the fighting of a the the of the of of fighting are of of of fighting a a are the fighting the are of are a of the of fighting fighting the the the are are of a a a the of a the fighting fighting a fighting of a the the fighting of fighting of of the a of of fighting a a are the of are fighting of a are the are fighting a a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the generated texts LSTM\n",
        "print(\"Generated Text (LSTM): \", generated_text_lstm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYbbUWi7djsF",
        "outputId": "abcd6310-37be-4071-fdf7-31212e8857c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text (LSTM):  He will have to look into this thing and he defending he lie and isn it his be him for anthony and s paul to be him between way has chances to be himself the time and obama as the final stretch of her ever vytt49yvoe campaign going near is a afraid for s compared hillary it the chances of its bigger that it just up be for stand the people has done is comey and during it front election she ought that has changed hillary desperation like before reason the same this of especially it s gone what her the revelation now the old candidate then the years is\n"
          ]
        }
      ]
    }
  ]
}